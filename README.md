# Awesome_Super_Prompts_Leaks: ChatGPT Jailbreaks , Leaks and Prompt Engineering

**Description**:
**Awesome_Super_Prompts_Leaks** is your gateway to a treasure trove of cutting-edge AI prompts.

**What will you find in here:**
- ChatGPT Jailbreaks
- GPT Assistants Prompt Leaks
- GPTs Prompt Injection
- LLM Prompt Security
- Super Prompts
- Prompt Hack
- Prompt Security
- Ai Prompt Engineering
- Adversarial Machine Learning

---

- [linexjlin/GPTs](https://github.com/linexjlin/GPTs)
- [LouisShark/chatgpt_system_prompt](https://github.com/LouisShark/chatgpt_system_prompt)
- [0xk1h0/ChatGPT_DAN](https://github.com/0xk1h0/ChatGPT_DAN)
- [EmbraceAGI/Awesome-AI-GPTs](https://github.com/EmbraceAGI/Awesome-AI-GPTs)
- [B3o/GPTS-Prompt-Collection](https://github.com/B3o/GPTS-Prompt-Collection)
- [1003715231/gptstore-prompts](https://github.com/1003715231/gptstore-prompts)
- [friuns2/Leaked-GPTs](https://github.com/friuns2/Leaked-GPTs)
- [adamidarrha/TopGptPrompts](https://github.com/adamidarrha/TopGptPrompts)
- [gogooing/Awesome-GPTs](https://github.com/gogooing/Awesome-GPTs)
- [verazuo/jailbreak_llms](https://github.com/verazuo/jailbreak_llms)
- [Cyberlion-Technologies/ChatGPT_DAN](https://github.com/Cyberlion-Technologies/ChatGPT_DAN)
- [fdac23/jailbreak-gpt](https://github.com/fdac23/jailbreak-gpt)
- [friuns2/BlackFriday-GPTs-Prompts](https://github.com/friuns2/BlackFriday-GPTs-Prompts)
- [friuns2/Awesome-GPTs-Big-List](https://github.com/friuns2/Awesome-GPTs-Big-List)
- [friuns2/Leaked-GPTs](https://github.com/friuns2/Leaked-GPTs)
- [TrustAIRLab/JailbreakLLMs](https://github.com/TrustAIRLab/JailbreakLLMs)
- [yes133/ChatGPT-Prompts-Jailbreaks-And-More](https://github.com/yes133/ChatGPT-Prompts-Jailbreaks-And-More)
- [ai-boost/awesome-prompts](https://github.com/ai-boost/awesome-prompts)
- [yunwei37/prompt-hacker-collections](https://github.com/yunwei37/prompt-hacker-collections)
- [FonduAI/awesome-prompt-injection](https://github.com/FonduAI/awesome-prompt-injection)
- [Cranot/chatbot-injections-exploits](https://github.com/Cranot/chatbot-injections-exploits)
- [TakSec/Prompt-Injection-Everywhere](https://github.com/TakSec/Prompt-Injection-Everywhere)
- [Valhall-ai/prompt-injection-mitigations](https://github.com/Valhall-ai/prompt-injection-mitigations)
- [AnthenaMatrix/AI-Prompt-Injection-List](https://github.com/AnthenaMatrix/AI-Prompt-Injection-List)
- [abilzerian/LLM-Prompt-Library](https://github.com/abilzerian/LLM-Prompt-Library)
- [0xeb/TheBigPromptLibrary](https://github.com/0xeb/TheBigPromptLibrary)
- [alphatrait/100000-ai-prompts-by-contentifyai](https://github.com/alphatrait/100000-ai-prompts-by-contentifyai)

---

## Keywords:
ChatGPT Assistant Leak
Jailbreak Prompts
GPT Hacking
GPT Agents Hack
System Prompt Leaks
Prompt Injection
LLM Security
Super Prompts
AI Adversarial Prompting
Prompt Design
Secure AI
Prompt Security
Prompt Development
Prompt Collection
GPT Prompt Library
Secret System Prompts
Creative Prompts
Prompt Crafting
Prompt Engineering
Prompt Vulnerability
